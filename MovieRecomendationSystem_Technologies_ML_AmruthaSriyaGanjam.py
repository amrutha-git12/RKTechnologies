# -*- coding: utf-8 -*-
"""MovieRecomendationSystem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ibYx4JG5kMBOjaAAeJM-Ojr3xZfgvKlD
"""

import numpy as np
import pandas as pd

credits_df= pd.read_csv("/content/credits.csv")
movies_df = pd.read_csv("/content/movies.csv")

credits_df

movies_df

credits_df.head()

movies_df.head()

movies_df = movies_df.merge(credits_df,on='title')

movies_df.shape

movies_df.info()

movies_df = movies_df[['movie_id','title','overview','genres','keywords','cast','crew']]

movies_df.head()

movies_df.info()

#missing values are present
movies_df.isnull().sum()

#drops all missing values
movies_df.dropna(inplace=True)

#values are duplicated or not
movies_df.duplicated().sum()

#iloc helps to select a specific col/row
movies_df.iloc[0].genres

import ast
#ast is a abstract syntax tree

#we can append them to name
def convert(obj):
  L=[]
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

#bcz of this we can remove the id/name from that specific col for easy understanding
movies_df['genres']=movies_df['genres'].apply(convert)
movies_df['keywords']=movies_df['keywords'].apply(convert)
movies_df.head()

import ast
def convert3(obj):
  L=[]
  counter = 0
  for i in ast.literal_eval(obj):
    if counter !=3:
      L.append(i['name'])
      counter +=1
    else:
      break
    return L

movies_df['cast']= movies_df['cast'].apply(convert3)

movies_df['cast'].head()

movies_df

def fetch_Director(obj):
  L = []
  for i in ast.literal_eval(obj):
    if i['job']=='Director':
      L.append(i['name'])
      break
  return L

movies_df['crew']= movies_df['crew'].apply(convert3)

movies_df

movies_df['overview'][0]

movies_df['overview']=movies_df['overview'].apply(lambda x:x.split())

movies_df

movies_df['genres']=movies_df['genres'].apply(lambda x:[i.replace(" ", " ") for i in x])
movies_df['keywords']=movies_df['keywords'].apply(lambda x:[i.replace(" ", " ") for i in x])

movies_df['cast'].head()

movies_df['cast'].isnull().sum()

movies_df['cast'] = movies_df['cast'].fillna('[]')

movies_df['cast'] = movies_df['cast'].apply(lambda x: [i.replace(" ", " ") for i in x if i is not None] or [])

movies_df['cast'].head()

movies_df['crew'].isnull().sum()

movies_df['crew'] = movies_df['crew'].fillna('[]')

movies_df['crew'] = movies_df['crew'].apply(lambda x: [i.replace(" ", " ") for i in x if i is not None] or [])

movies_df['crew'].head()

movies_df

movies_df['tags'] = movies_df['overview'] + movies_df['keywords'] + movies_df['cast']+movies_df['crew']
movies_df

new_df = movies_df[['movie_id','title','tags']]
new_df

new_df['tags'] = new_df['tags'].apply(lambda x:' '.join(x))

new_df

new_df['tags'][0]

new_df['tags']=new_df['tags'].apply(lambda X:X.lower())

new_df.head()

#converts given text to a vector accordingly frequency count
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words='english')

#dict of tokens by default the tokens are words seperated by spaces like punctuations
cv.fit_transform(new_df['tags']).toarray().shape

vectors = cv.fit_transform(new_df['tags']).toarray()

vectors[0]

print(cv)

print(dir(cv))

len(cv.get_feature_names_out())

import nltk

#stemming is a process for reducing a word to its word stem
#that suffix and prefix or to the roots of the words known as lemma its imp in Natural Language
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():
    y.append(ps.stem(i))
  return " ".join(y)

from nltk.stem import PorterStemmer
ps = PorterStemmer()

new_df['tags'] = new_df['tags'].apply(lambda x: " ".join([ps.stem(word) for word in x.split()]))

new_df['tags']= new_df['tags'].apply(stem)

from sklearn.metrics.pairwise import cosine_similarity

cosine_similarity(vectors)

cosine_similarity(vectors).shape

similarity = cosine_similarity(vectors)

similarity[0]

similarity[0].shape

#sorted list
sorted(list(enumerate(similarity[0])),reverse= True,key=lambda x:x[1])[1:6]

def recommend(movie):
  movie_index = new_df[new_df['title']==movie].index[0]
  distances=similarity[movie_index]
  movies_list= sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]

  for i in movies_list:
    print(new_df.iloc[i[0]].title)

recommend('Avatar')

recommend('Iron Man')

recommend('Liar Liar')

recommend('Avengers: Age of Ultron')

recommend('Pinocchio')

recommend('Ted')